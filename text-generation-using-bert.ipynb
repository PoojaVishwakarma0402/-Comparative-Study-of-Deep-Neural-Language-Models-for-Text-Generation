{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7297075,"sourceType":"datasetVersion","datasetId":4232737},{"sourceId":7302768,"sourceType":"datasetVersion","datasetId":4236811}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-02T09:26:31.381029Z","iopub.execute_input":"2024-01-02T09:26:31.381770Z","iopub.status.idle":"2024-01-02T09:26:48.940551Z","shell.execute_reply.started":"2024-01-02T09:26:31.381725Z","shell.execute_reply":"2024-01-02T09:26:48.939192Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport torch.nn as nn\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:40:51.329251Z","iopub.execute_input":"2024-01-02T09:40:51.329923Z","iopub.status.idle":"2024-01-02T09:40:57.306624Z","shell.execute_reply.started":"2024-01-02T09:40:51.329892Z","shell.execute_reply":"2024-01-02T09:40:57.305850Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Load and preprocess the Shakespeare dataset\nwith open(\"/kaggle/input/shakespeare-txt/shakespeare.txt\", \"r\", encoding=\"utf-8\") as file:\n    data = file.read()","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:42:06.129272Z","iopub.execute_input":"2024-01-02T09:42:06.129663Z","iopub.status.idle":"2024-01-02T09:42:06.215155Z","shell.execute_reply.started":"2024-01-02T09:42:06.129632Z","shell.execute_reply":"2024-01-02T09:42:06.214240Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Tokenize the dataset\ntokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\ntokenized_text = tokenizer.encode(data, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:42:10.194084Z","iopub.execute_input":"2024-01-02T09:42:10.194804Z","iopub.status.idle":"2024-01-02T09:42:25.891400Z","shell.execute_reply.started":"2024-01-02T09:42:10.194771Z","shell.execute_reply":"2024-01-02T09:42:25.890585Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44745e7091de4502a0bda621b74744f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35a64c1a448c4a3083d158e9481a7f2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4c4c4cb72fe4d4c9dd7e8e292ffe49a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cc48e3f62fe451dacf6ce677e36d153"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (1850440 > 1024). Running this sequence through the model will result in indexing errors\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define a custom dataset\nclass ShakespeareDataset(Dataset):\n    def __init__(self, tokenized_text, seq_length=50):\n        self.tokenized_text = tokenized_text\n        self.seq_length = seq_length\n\n    def __len__(self):\n        return len(self.tokenized_text[0]) - self.seq_length\n\n    def __getitem__(self, idx):\n        return self.tokenized_text[0][idx : idx + self.seq_length]","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:44:35.999343Z","iopub.execute_input":"2024-01-02T09:44:36.000038Z","iopub.status.idle":"2024-01-02T09:44:36.006418Z","shell.execute_reply.started":"2024-01-02T09:44:36.000002Z","shell.execute_reply":"2024-01-02T09:44:36.005412Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Create a DataLoader for training\ndataset = ShakespeareDataset(tokenized_text)\ndataloader = DataLoader(dataset, batch_size=6, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:45:34.848997Z","iopub.execute_input":"2024-01-02T09:45:34.849843Z","iopub.status.idle":"2024-01-02T09:45:34.854633Z","shell.execute_reply.started":"2024-01-02T09:45:34.849815Z","shell.execute_reply":"2024-01-02T09:45:34.853491Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Define the GPT-2 model\nconfig = GPT2Config.from_pretrained(\"gpt2\")\nmodel = GPT2LMHeadModel(config)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:45:38.749043Z","iopub.execute_input":"2024-01-02T09:45:38.749693Z","iopub.status.idle":"2024-01-02T09:45:41.662509Z","shell.execute_reply.started":"2024-01-02T09:45:38.749662Z","shell.execute_reply":"2024-01-02T09:45:41.661492Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Fine-tune the model on the Shakespeare dataset\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:45:44.654080Z","iopub.execute_input":"2024-01-02T09:45:44.654448Z","iopub.status.idle":"2024-01-02T09:45:44.796207Z","shell.execute_reply.started":"2024-01-02T09:45:44.654421Z","shell.execute_reply":"2024-01-02T09:45:44.795305Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"GPT2LMHeadModel(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:45:48.554403Z","iopub.execute_input":"2024-01-02T09:45:48.554765Z","iopub.status.idle":"2024-01-02T09:45:48.561442Z","shell.execute_reply.started":"2024-01-02T09:45:48.554736Z","shell.execute_reply":"2024-01-02T09:45:48.560429Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"num_epochs = 3\nfor epoch in range(num_epochs):\n    total_loss = 0\n    for batch in tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n        batch = batch.to(device)\n        optimizer.zero_grad()\n        outputs = model(input_ids=batch, labels=batch)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    average_loss = total_loss / len(dataloader)\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-02T09:45:51.634811Z","iopub.execute_input":"2024-01-02T09:45:51.635171Z","iopub.status.idle":"2024-01-02T09:48:37.194942Z","shell.execute_reply.started":"2024-01-02T09:45:51.635144Z","shell.execute_reply":"2024-01-02T09:48:37.193751Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Epoch 1/3:   0%|          | 1306/308399 [02:45<10:48:40,  7.89it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 11\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m average_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Average Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maverage_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Save the fine-tuned model\nmodel.save_pretrained(\"shakespeare_fine_tuned_gpt2\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate text using the fine-tuned model\nmodel.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_text = \"To be or not to be\"\ninput_ids = tokenizer.encode(seed_text, return_tensors=\"pt\").to(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for _ in range(100):\n    output = model.generate(input_ids, max_length=50, num_beams=5, temperature=0.7)\n    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n    print(generated_text)\n    input_ids = tokenizer.encode(seed_text + \" \" + generated_text, return_tensors=\"pt\").to(device)","metadata":{},"execution_count":null,"outputs":[]}]}